{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFNaQzBlrfy"
      },
      "source": [
        "## Домашнее задание\n",
        "\n",
        "1. Обучите CNN (самописная) на CIFAR-100.\n",
        "2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.\n",
        "3. *Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v5dpvBRrekDP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S04vtRqcekDU",
        "outputId": "c95bef09-165c-4386-b078-b3152a3f5d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True)\n",
        "\n",
        "\n",
        "class MyOwnCifar(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, transform=None):\n",
        "        self._base_dataset = init_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._base_dataset[idx][0]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, self._base_dataset[idx][1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_valid_split(Xt):\n",
        "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
        "    return X_train, X_test"
      ],
      "metadata": {
        "id": "3wYJgO_Bb3xs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_actions = transforms.Compose([transforms.Resize(44),\n",
        "                                    transforms.RandomCrop(32, padding=4), \n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
      ],
      "metadata": {
        "id": "enZFMWUQsKjq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "id": "iyPJ3mMLsNqG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = dataset.classes"
      ],
      "metadata": {
        "id": "EsqYPEqrsk4F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "for img, lbl in train_loader:\n",
        "    print(img.shape)\n",
        "    print(classes[lbl[0]])\n",
        "    plt.imshow(img[0].permute(1, 2, 0))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "lS0a0ZymsPPs",
        "outputId": "ff9ee2c9-b1f7-410a-e2dc-c558311ad2b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "keyboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ct7V-AM3t7Dp",
        "outputId": "7166aee2-ea80-4638-bf33-db72d022a72a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k25KQrWRekDa",
        "outputId": "6fd5f274-f3e4-4661-f1a8-fde04ed53020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (enc_conv0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (enc_conv1): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "  )\n",
            "  (enc_conv2): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "  )\n",
            "  (out): Linear(in_features=1024, out_features=100, bias=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dp): Dropout(p=0.4, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, bn_momentum = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_conv0 = nn.Sequential(\n",
        "                      nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(64, momentum=bn_momentum),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(128, momentum=bn_momentum),\n",
        "                      nn.ReLU()\n",
        "                      )\n",
        "        \n",
        "        self.enc_conv1 = nn.Sequential(\n",
        "                      nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(512, momentum=bn_momentum),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "                      nn.ReLU()\n",
        "                  )\n",
        "        \n",
        "        self.enc_conv2 = nn.Sequential(\n",
        "                      nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(256, momentum=bn_momentum),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(128, momentum=bn_momentum),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "                      nn.BatchNorm2d(64, momentum=bn_momentum),\n",
        "                      nn.ReLU()\n",
        "                  )\n",
        "        \n",
        "        self.out = torch.nn.Linear(1024, 100)\n",
        "        self.pool =  nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "     \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(self.enc_conv0(x))\n",
        "        x = self.pool(self.enc_conv1(x))\n",
        "        x = self.pool(self.enc_conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dp(x)\n",
        "        return self.out(x)\n",
        "        \n",
        "net = Net().to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4D1dBQxiekDd"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOkJ0P6jKODC",
        "outputId": "d17333aa-60e9-48f7-9747-bf6f67a0ec80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4          [-1, 128, 32, 32]          73,856\n",
            "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
            "              ReLU-6          [-1, 128, 32, 32]               0\n",
            "         MaxPool2d-7          [-1, 128, 16, 16]               0\n",
            "            Conv2d-8          [-1, 256, 16, 16]         295,168\n",
            "       BatchNorm2d-9          [-1, 256, 16, 16]             512\n",
            "             ReLU-10          [-1, 256, 16, 16]               0\n",
            "           Conv2d-11          [-1, 512, 16, 16]       1,180,160\n",
            "      BatchNorm2d-12          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-13          [-1, 512, 16, 16]               0\n",
            "           Conv2d-14          [-1, 256, 16, 16]       1,179,904\n",
            "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
            "             ReLU-16          [-1, 256, 16, 16]               0\n",
            "        MaxPool2d-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 128, 8, 8]         295,040\n",
            "      BatchNorm2d-22            [-1, 128, 8, 8]             256\n",
            "             ReLU-23            [-1, 128, 8, 8]               0\n",
            "           Conv2d-24             [-1, 64, 8, 8]          73,792\n",
            "      BatchNorm2d-25             [-1, 64, 8, 8]             128\n",
            "             ReLU-26             [-1, 64, 8, 8]               0\n",
            "        MaxPool2d-27             [-1, 64, 4, 4]               0\n",
            "          Dropout-28                 [-1, 1024]               0\n",
            "           Linear-29                  [-1, 100]         102,500\n",
            "================================================================\n",
            "Total params: 3,795,620\n",
            "Trainable params: 3,795,620\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.55\n",
            "Params size (MB): 14.48\n",
            "Estimated Total Size (MB): 26.04\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-toyvCVekDf",
        "outputId": "4bc9ce32-e15c-449f-ae71-6b5c09c4aa87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/372]. Loss: 0.038. Acc: 0.016. Test acc: 0.009\n",
            "Epoch [1/5]. Step [301/372]. Loss: 0.035. Acc: 0.031. Test acc: 0.063\n",
            "Epoch [2/5]. Step [1/372]. Loss: 0.032. Acc: 0.047. Test acc: 0.075\n",
            "Epoch [2/5]. Step [301/372]. Loss: 0.032. Acc: 0.071. Test acc: 0.100\n",
            "Epoch [3/5]. Step [1/372]. Loss: 0.031. Acc: 0.086. Test acc: 0.106\n",
            "Epoch [3/5]. Step [301/372]. Loss: 0.030. Acc: 0.096. Test acc: 0.143\n",
            "Epoch [4/5]. Step [1/372]. Loss: 0.029. Acc: 0.141. Test acc: 0.128\n",
            "Epoch [4/5]. Step [301/372]. Loss: 0.029. Acc: 0.127. Test acc: 0.149\n",
            "Epoch [5/5]. Step [1/372]. Loss: 0.027. Acc: 0.133. Test acc: 0.140\n",
            "Epoch [5/5]. Step [301/372]. Loss: 0.028. Acc: 0.157. Test acc: 0.153\n",
            "Training is finished!\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "net.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            net.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = net(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "        \n",
        "        net.train()\n",
        "        \n",
        "print('Training is finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50"
      ],
      "metadata": {
        "id": "5Uo3a5Ijwp1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "print(resnet50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pir2sEjyvrv3",
        "outputId": "ee4a3b89-dbf2-4c2e-8263-ccf4a649229c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(resnet50.to(device), input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P_75cK8yfnn",
        "outputId": "31a2d081-85bb-464c-d77a-5bb47c16e901"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,557,032\n",
            "Trainable params: 25,557,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.56\n",
            "Params size (MB): 97.49\n",
            "Estimated Total Size (MB): 384.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in list(resnet50.parameters())[:]:\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "OXaIlijFw7uc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.fc = nn.Linear(2048, 100)\n",
        "\n",
        "summary(resnet50.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l79qD4mHxE0J",
        "outputId": "51a6b962-71da-407e-f681-33ad96611dcc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
            "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "             ReLU-15            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "             ReLU-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
            "             ReLU-29             [-1, 64, 8, 8]               0\n",
            "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
            "             ReLU-32             [-1, 64, 8, 8]               0\n",
            "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "             ReLU-35            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "             ReLU-39            [-1, 128, 8, 8]               0\n",
            "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
            "             ReLU-42            [-1, 128, 4, 4]               0\n",
            "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-47            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
            "             ReLU-61            [-1, 128, 4, 4]               0\n",
            "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
            "             ReLU-64            [-1, 128, 4, 4]               0\n",
            "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-67            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
            "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
            "             ReLU-71            [-1, 128, 4, 4]               0\n",
            "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
            "             ReLU-74            [-1, 128, 4, 4]               0\n",
            "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-77            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
            "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
            "             ReLU-81            [-1, 256, 4, 4]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-89           [-1, 1024, 2, 2]               0\n",
            "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
            "             ReLU-93            [-1, 256, 2, 2]               0\n",
            "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
            "             ReLU-96            [-1, 256, 2, 2]               0\n",
            "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-99           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
            "            ReLU-103            [-1, 256, 2, 2]               0\n",
            "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
            "            ReLU-106            [-1, 256, 2, 2]               0\n",
            "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-109           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
            "            ReLU-113            [-1, 256, 2, 2]               0\n",
            "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
            "            ReLU-116            [-1, 256, 2, 2]               0\n",
            "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-119           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
            "            ReLU-123            [-1, 256, 2, 2]               0\n",
            "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
            "            ReLU-126            [-1, 256, 2, 2]               0\n",
            "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-129           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
            "            ReLU-133            [-1, 256, 2, 2]               0\n",
            "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
            "            ReLU-136            [-1, 256, 2, 2]               0\n",
            "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-139           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-143            [-1, 512, 2, 2]               0\n",
            "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-146            [-1, 512, 1, 1]               0\n",
            "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-151           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-155            [-1, 512, 1, 1]               0\n",
            "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-158            [-1, 512, 1, 1]               0\n",
            "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-161           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-165            [-1, 512, 1, 1]               0\n",
            "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-168            [-1, 512, 1, 1]               0\n",
            "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-171           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                  [-1, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,712,932\n",
            "Trainable params: 204,900\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.86\n",
            "Params size (MB): 90.46\n",
            "Estimated Total Size (MB): 96.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = resnet50.to(device)"
      ],
      "metadata": {
        "id": "vO85uLzY1Nza"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_actions = transforms.Compose([transforms.Resize(256),\n",
        "                                    transforms.RandomCrop(224, padding=4), \n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                         std=[0.229, 0.224, 0.225])])\n",
        "valid_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, train_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)"
      ],
      "metadata": {
        "id": "UEPVCyJuxMqB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=1)"
      ],
      "metadata": {
        "id": "UlOPel8YxG0L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name, param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "C8aAaOl5xd4T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "resnet50.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            resnet50.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = resnet50(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "        resnet50.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWSx39fHxjPp",
        "outputId": "a820ba04-ef66-493c-9d10-dc898ec96d79"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/372]. Loss: 0.037. Acc: 0.016. Test acc: 0.008\n",
            "Epoch [1/5]. Step [301/372]. Loss: 0.020. Acc: 0.395. Test acc: 0.503\n",
            "Epoch [2/5]. Step [1/372]. Loss: 0.014. Acc: 0.508. Test acc: 0.524\n",
            "Epoch [2/5]. Step [301/372]. Loss: 0.014. Acc: 0.534. Test acc: 0.541\n",
            "Epoch [3/5]. Step [1/372]. Loss: 0.012. Acc: 0.570. Test acc: 0.520\n",
            "Epoch [3/5]. Step [301/372]. Loss: 0.012. Acc: 0.565. Test acc: 0.568\n",
            "Epoch [4/5]. Step [1/372]. Loss: 0.012. Acc: 0.562. Test acc: 0.558\n",
            "Epoch [4/5]. Step [301/372]. Loss: 0.012. Acc: 0.582. Test acc: 0.572\n",
            "Epoch [5/5]. Step [1/372]. Loss: 0.013. Acc: 0.547. Test acc: 0.557\n",
            "Epoch [5/5]. Step [301/372]. Loss: 0.012. Acc: 0.586. Test acc: 0.576\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDs0HOHIQjjH"
      },
      "source": [
        "## Аугментация данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1XV-mstygbK"
      },
      "source": [
        "from scipy import misc\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYn1hiUJTJA_"
      },
      "source": [
        "transformations = transforms.Compose([\n",
        "    transforms.Resize(size=(255, 255), ),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=2, contrast=2),\n",
        "    transforms.CenterCrop(size=224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, transformations)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN5Ho8zjTJBA"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in list(resnet50.parameters())[:]:\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "SvyZMFRy3tB1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.fc = nn.Linear(2048, 100)\n",
        "resnet50 = resnet50.to(device)"
      ],
      "metadata": {
        "id": "a4NoE1923tLt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name, param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "zs_8tCMhcXja"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwepdC6DTJBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83b853b-3240-4fe6-aca0-afc22258a2e0"
      },
      "source": [
        "num_epochs = 5\n",
        "resnet50.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            resnet50.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = resnet50(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "        resnet50.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/372]. Loss: 0.036. Acc: 0.000. Test acc: 0.011\n",
            "Epoch [1/5]. Step [301/372]. Loss: 0.028. Acc: 0.189. Test acc: 0.396\n",
            "Epoch [2/5]. Step [1/372]. Loss: 0.024. Acc: 0.297. Test acc: 0.412\n",
            "Epoch [2/5]. Step [301/372]. Loss: 0.023. Acc: 0.301. Test acc: 0.464\n",
            "Epoch [3/5]. Step [1/372]. Loss: 0.025. Acc: 0.266. Test acc: 0.454\n",
            "Epoch [3/5]. Step [301/372]. Loss: 0.022. Acc: 0.326. Test acc: 0.474\n",
            "Epoch [4/5]. Step [1/372]. Loss: 0.017. Acc: 0.477. Test acc: 0.461\n",
            "Epoch [4/5]. Step [301/372]. Loss: 0.021. Acc: 0.337. Test acc: 0.489\n",
            "Epoch [5/5]. Step [1/372]. Loss: 0.021. Acc: 0.281. Test acc: 0.492\n",
            "Epoch [5/5]. Step [301/372]. Loss: 0.021. Acc: 0.346. Test acc: 0.496\n",
            "Training is finished!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Копия блокнота \"lesson_4.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}